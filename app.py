import streamlit as st
import os
import pandas as pd
from llama_index.core import (
    VectorStoreIndex,
    SimpleDirectoryReader,
    StorageContext,
    load_index_from_storage,
    PromptTemplate
)
from llama_index.experimental.query_engine import PandasQueryEngine, PandasInstructionParser
import logging
import sys

# Set OpenAI API key from secrets
os.environ['OPENAI_API_KEY'] = st.secrets["openai_api_key"]

# Configure logging
logging.basicConfig(stream=sys.stdout, level=logging.INFO)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))

# Set page config
st.set_page_config(
    page_title="Data Analysis Chatbot",
    page_icon="ðŸ¤–",
    layout="wide"
)

# Initialize session state for chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Title and description
st.title("ðŸ“Š Data Analysis Chatbot")
st.markdown("Ask questions about your data and get instant insights!")

# Load the data and index
# @st.cache_resource
def load_data():
    # Load CSV data
    file = st.file_uploader("Upload your CSV file", type=["csv"])
    if file is None:
        st.stop()
    df = pd.read_csv(file)
    
    # Load or create vector index
    PERSIST_DIR = "./storage"
    if not os.path.exists(PERSIST_DIR):
        documents = SimpleDirectoryReader("data").load_data()
        index = VectorStoreIndex.from_documents(documents)
        index.storage_context.persist(persist_dir=PERSIST_DIR)
    else:
        storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)
        index = load_index_from_storage(storage_context)
    
    return df, index

# Load data
df, index = load_data()

instruction_str = (
    "1. Convert the query to executable Python code using Pandas.\n"
    "2. The final line of code should be a Python expression that can be called with the `eval()` function.\n"
    "3. The code should represent a solution to the query.\n"
    "4. PRINT ONLY THE EXPRESSION.\n"
    "5. Do not quote the expression.\n"
)

pandas_prompt_str = (
    "You are working with a pandas dataframe in Python.\n"
    "The name of the dataframe is `df`.\n"
    "This is the result of `print(df.head())`:\n"
    "{df_str}\n\n"
    "Follow these instructions:\n"
    "{instruction_str}\n"
    "Query: {query_str}\n\n"
    "Expression:"
)

# response_synthesis_prompt_str = (
#     "Given an input question, synthesize a response from the query results.\n"
#     "Query: {query_str}\n\n"
#     "Pandas Instructions (optional):\n{pandas_instructions}\n\n"
#     "Pandas Output: {pandas_output}\n\n"
#     "Response: "
# )

pandas_prompt = PromptTemplate(pandas_prompt_str).partial_format(
    instruction_str=instruction_str, df_str=df.head(5)
)
pandas_output_parser = PandasInstructionParser(df)
# response_synthesis_prompt = PromptTemplate(response_synthesis_prompt_str)

# Create query engine
query_engine = PandasQueryEngine(df=df, verbose=True, pandas_prompt=pandas_prompt, pandas_output_parser=pandas_output_parser)

# Display chat messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Chat input
if prompt := st.chat_input("Ask a question about your data"):
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Display user message
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Get bot response
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            response = query_engine.query(prompt)
            st.markdown(str(response))
            st.session_state.messages.append({"role": "assistant", "content": str(response)})



